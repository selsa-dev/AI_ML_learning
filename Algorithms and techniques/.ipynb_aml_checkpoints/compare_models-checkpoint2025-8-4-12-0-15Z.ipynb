{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset: Study hours, previous exam scores, and pass/fail labels\n",
        "data = {\n",
        "    'StudyHours': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'PrevExamScore': [30, 40, 45, 50, 60, 65, 70, 75, 80, 85],\n",
        "    'Pass': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]  # 0 = Fail, 1 = Pass\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the first few rows of the data\n",
        "print(df.head())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Features (X) and Target (y)\n",
        "X = df[['StudyHours', 'PrevExamScore']]  # Features\n",
        "y = df['Pass']  # Target variable (0 = Fail, 1 = Pass)\n",
        "\n",
        "# Split data into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training data: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Testing data: {X_test.shape}, {y_test.shape}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Logistic Regression model\n",
        "logreg_model = LogisticRegression()\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the test set\n",
        "y_pred_logreg = logreg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Logistic Regression model\n",
        "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_logreg}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Decision Tree Classifier\n",
        "tree_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the Decision Tree model\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the test set\n",
        "y_pred_tree = tree_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Decision Tree model\n",
        "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
        "print(f\"Decision Tree Accuracy: {accuracy_tree}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Logistic Regression\n",
        "print(\"Logistic Regression:\")\n",
        "print(f\"Accuracy: {accuracy_logreg}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_logreg))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_logreg))\n",
        "\n",
        "# Evaluate Decision Tree\n",
        "print(\"Decision Tree:\")\n",
        "print(f\"Accuracy: {accuracy_tree}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_tree))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_tree))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the decision tree\n",
        "plt.figure(figsize=(12,8))\n",
        "tree.plot_tree(tree_model, feature_names=['StudyHours', 'PrevExamScore'], class_names=['Fail', 'Pass'], filled=True)\n",
        "plt.title('Decision Tree for Classifying Pass/Fail')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression is simpler and works well when the relationship between the features and the target is linear.\n",
        "\n",
        "Decision trees offer more flexibility and can capture nonlinear relationships, but they can overfit if not properly tuned (e.g., by limiting the depth of the tree)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}