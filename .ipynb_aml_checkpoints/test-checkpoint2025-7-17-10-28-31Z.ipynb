{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow Version: \" + tf.__version__)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "TensorFlow Version: 2.19.0\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1755100436549
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://book24.ru'  # Replace with the URL of the website you want to scrape\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    print('Request successful!')\n",
        "else:\n",
        "    print('Failed to retrieve the webpage')\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Print the title of the webpage to verify\n",
        "print(soup.title.text)\n",
        "\n",
        "# Find the table containing the data\n",
        "table = soup.find('main', {'id': 'main'})  # Replace 'data-table' with the actual id or class of the table\n",
        "\n",
        "# Extract table rows\n",
        "rows = table.find_all('a')\n",
        "\n",
        "# Loop through the rows and extract data\n",
        "data = []\n",
        "for row in rows:\n",
        "    cols = [row.text.strip()]\n",
        "    data.append(cols)\n",
        "\n",
        "# Convert the data into a pandas DataFrame for easier manipulation\n",
        "df = pd.DataFrame(data)  # Replace with actual column names\n",
        "print(df.head(10))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Request successful!\nBook24.ru – книжный интернет магазин – купить книги, читать отзывы. Доставка по Москве, СПб и в любой город - Главная страница\n                           0\n0         Книги с автографом\n1  Художественная литература\n2         Боевики и триллеры\n3            Военные боевики\n4         Зарубежные боевики\n5       Криминальные боевики\n6            Русские боевики\n7                   Триллеры\n8                  Детективы\n9       Зарубежные детективы\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1755250208045
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Send an HTTP request to the webpage\n",
        "url = 'https://en.wikipedia.org/wiki/Cloud-computing_comparison'  \n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Print the title of the webpage to verify\n",
        "print(\"Title: \" + soup.title.text)\n",
        "\n",
        "# Find the table containing the data (selecting the first table by default)\n",
        "table = soup.find('table')\n",
        "\n",
        "# Extract table rows\n",
        "rows = table.find_all('tr')\n",
        "\n",
        "# Extract headers from the first row (using <th> tags)\n",
        "headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
        "\n",
        "# Loop through the rows and extract data (skip the first row with headers)\n",
        "data = []\n",
        "for row in rows[1:]:  # Start from the second row onwards\n",
        "    cols = row.find_all('td')\n",
        "    cols = [col.text.strip() for col in cols]\n",
        "    data.append(cols)\n",
        "\n",
        "# Convert the data into a pandas DataFrame, using the extracted headers as column names\n",
        "df = pd.DataFrame(data, columns=headers)\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify\n",
        "print(df.head())  \n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('scraped_data.csv', index=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Title: Cloud-computing comparison - Wikipedia\n                      Provider Launched Block storage Assignable IPs  \\\n0        Google Cloud Platform     2013           Yes             No   \n1  Oracle Cloud Infrastructure     2014           Yes            Yes   \n2          Amazon Web Services     2006           Yes            Yes   \n3                    IBM Cloud     2005           Yes            Yes   \n4              Microsoft Azure     2010           Yes            Yes   \n\n  SMTP support IOPS Guaranteed minimum Security  \\\n0        No[1]                     Yes   Yes[2]   \n1          Yes                     Yes   Yes[5]   \n2   Partial[6]                     Yes   Yes[7]   \n3        No[9]                     Yes  Yes[10]   \n4      Yes[11]                     Yes  Yes[12]   \n\n                                           Locations             Notes  \n0  br, ca, cl, us, be, ch, de, es, fi, it, po, nl...  SMTP blocked.[4]  \n1  us, ca, br, de, uk, nl, ch, in, aus, jp, kr, saud                    \n2  us, ca, br, ie, de, uk, cn, sg, au, jp, kr, in...   List of bugs[8]  \n3  us, gb, fr, de, nl, in, au, hk, kr, it, jp, no...                    \n4  ca, us, br, ie, nl, de, uk, cn, au, jp, in, kr...  List of bugs[13]  \n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1755250270176
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import missingno as msno  # Optional: for visualizing missing data\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}